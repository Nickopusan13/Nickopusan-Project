![Google Maps UI Screenshot](https://github.com/Nickopusan13/Nickopusan-Portofolio/blob/master/Google%20Maps%20Scraper/Image/Google%20Maps%20UI.png?raw=true)
# Google Maps Scraper
## Overview
The **Google Maps Scraper** is a Python-based tool designed to extract business information from Google Maps based on a user-provided search query (e.g., "restaurants in New York"). It leverages asynchronous web scraping with Playwright, processes the raw data for consistency, and provides a graphical user interface (GUI) built with Tkinter. The scraped data is saved as CSV files, both in raw and cleaned formats, making it ready for analysis or further use.

This project is ideal for users who need structured data from Google Maps, such as business names, ratings, addresses, and websites, without manually collecting it.

## Features
- **Web Scraping**: Automates browser interaction with Google Maps using Playwright to collect business data.
- **Data Cleaning**: Formats and removes inconsistencies from the scraped data for better usability.
- **Graphical User Interface**: Offers an intuitive Tkinter-based GUI with a visually appealing starry night background.
- **Asynchronous Operations**: Uses `asyncio` to handle scraping tasks efficiently, keeping the UI responsive.
## Components
The project is split into three main files, each with a specific role:
### 1. [`main.py`](Scraper/main.py)
**Purpose**: Serves as the entry point of the application, managing the GUI and coordinating the scraping and cleaning processes.
- **StarryBackground Class**:
  - Creates a canvas with a black background, twinkling stars, and a moon with craters for aesthetic appeal.
  - Stars twinkle randomly every 500 milliseconds to enhance the user experience.
- **ScraperApp Class**:
  - **UI Setup**: Initializes a window with:
    - A search entry field for the user to input a query.
    - A "Start Scraping" button to begin the process.
    - A status label at the bottom to display progress or results.
  - **Scraping Trigger**: When the button is clicked, the `start_scraping` method:
    - Validates the search term (ensures itâ€™s not empty).
    - Disables the button to prevent multiple runs.
    - Starts a separate thread for the scraping task to avoid freezing the GUI.
  - **Asynchronous Task Management**: The `run_scraping_task` method:
    - Uses `asyncio.run` to execute the `async_scrape` function.
    - Instantiates a `GoogleMapsScraper` object to scrape data.
    - Calls a `DataCleaner` object to clean the scraped data.
    - Updates the UI with success messages (file paths) or errors via a status queue.
  - **Feedback**: Displays pop-up messages for success or failure and resets the UI when done.
### 2. [`scraper.py`](Scraper/scraper.py)
**Purpose**: Contains the `GoogleMapsScraper` class, which handles the core web scraping logic using Playwright.

- **Initialization**:
  - Sets up an output directory (`output`) and a set (`seen_names`) to track unique business names and avoid duplicates.
  - Defines the base URL as `https://www.google.com/maps?hl=en`.
- **CSV Handling**:
  - Creates a CSV file named after the sanitized search query (e.g., `restaurants_in_New_York.csv`).
  - Writes headers: `Name`, `Rating`, `Review`, `Address`, `Price`, `Phone Number`, `Website`, `Description`, `URL`.
- Scraping Process (`start_url` method):
  - Launches a headless Chromium browser with Playwright.
  - Navigates to Google Maps, inputs the search query, and submits it.
  - Waits for search results to load and scrolls through them to ensure all items are visible.
- **Scrolling Logic** (`scroll_page` method):
  - Scrolls the results feed incrementally until the "end of page" message appears.
  - Triggers the `get_data` method to extract data from loaded items.
- **Data Extraction** (`get_data` method):
  - Identifies all business listings on the page.
  - For each item:
    - Clicks to open its details.
    - Extracts fields like name, rating, review count, address, price, phone number, website, description, and URL using CSS selectors.
    - Skips duplicates based on the business name.
    - Writes the data to the CSV file.
  - Includes a progress callback to update the GUI with the current business being scraped.
### 3. [`cleaner.py`](Scraper/cleaner.py)
**Purpose**: Contains the `DataCleaner` class, which processes and refines the raw scraped data.

- **Cleaning Functions**:
  - `clean_description`: Strips whitespace from text fields or returns None if empty.
  - `clean_rating`: Converts ratings to floats, handling commas or invalid formats.
  - `clean_review`: Extracts numeric review counts, removing parentheses and hyphens.
  - `clean_price`: Removes currency symbols and extra spaces from price data.
  - `clean_phone`: Strips whitespace from phone numbers.
  - `clean_website`: Filters out invalid URLs (e.g., Google business links) and ensures proper format.
- Data Processing (`clean_scraped_data` method):
  - Reads the raw CSV file using Pandas.
  - Applies cleaning functions to each row.
  - Removes duplicate rows and entries missing a name.
  - Saves the cleaned data to a new file prefixed with cleaned_ (e.g., `cleaned_restaurants_in_New_York.csv`).
## Usage
1. **Run the Application**:
    - Execute python main.py to launch the GUI.
2. **Enter Search Term**:
    - Type a query (e.g., "cafes in San Francisco") into the search field.
3. **Start Scraping**:
    - Click "Start Scraping" to begin.
4. **Monitor Progress**:
    - Watch the status bar for updates (e.g., "Scraping Starbucks...").
5. **View Results**:
    - On completion, a pop-up shows the paths to the raw and cleaned CSV files (e.g., `output/restaurants.csv` and `output/cleaned_restaurants.csv`).

![Google Maps Output](https://github.com/Nickopusan13/Nickopusan-Portofolio/blob/master/Google%20Maps%20Scraper/Image/Google%20Maps%20Output.png)
